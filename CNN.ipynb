{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92cc563-6167-4006-9722-53e7ef0f02b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.21.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl (178.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchvision-0.21.0%2Bcpu-cp311-cp311-linux_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: sympy, filelock, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed filelock-3.13.1 sympy-1.13.1 torch-2.6.0+cpu torchaudio-2.6.0+cpu torchvision-0.21.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import datasets\n",
    "    from torchvision.transforms import ToTensor\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "except ImportError:\n",
    "    !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import datasets\n",
    "    from torchvision.transforms import ToTensor\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "try:\n",
    "    from skimage.feature import hog\n",
    "    from skimage.color import rgb2gray\n",
    "except ImportError:\n",
    "    !pip3 install scikit-image\n",
    "    from skimage.feature import hog\n",
    "    from skimage.color import rgb2gray\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "182f7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import datasets\n",
    "    from torchvision.transforms import ToTensor\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "except ImportError:\n",
    "    !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "try:\n",
    "    from skimage.feature import hog\n",
    "    from skimage.color import rgb2gray\n",
    "except ImportError:\n",
    "    !pip3 install scikit-image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d83075",
   "metadata": {},
   "source": [
    "## Arquitectura CNN modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33cfa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la clase CNN\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    # input_channels: número de canales de entrada \n",
    "    # conv_lavers: número de capas convolucionales\n",
    "    # first_conv_filters: num filtros primera capa, se duplicarán en cada capa\n",
    "    # con_kernel_size: tam filtros convolucionales (cuadrados)\n",
    "    # batch_norm: booleano para usar normalización por lotes\n",
    "    # hidden_mlp_layers: número de neuronas en la capa oculta de la red MLP\n",
    "    # output_neurons: número de neuronas de salida\n",
    "    def __init__(self, input_channels, conv_lavers, first_conv_filters, conv_kernel_size, batch_norm, hidden_mlp_layers, output_neurons):\n",
    "        \n",
    "        # Construtor \n",
    "        super(CNN, self).__init__()  \n",
    "\n",
    "        # Arrays auxiliares\n",
    "        layers = [] # Contiene las capas\n",
    "\n",
    "        # Definición de capas según los parámetros\n",
    "        for _ in range(conv_lavers): # Bucle para el número de capas convolucionades pasadas por parámetro\n",
    "            layers.append(nn.Conv2d(in_channels=input_channels, out_channels=first_conv_filters, kernel_size=conv_kernel_size))\n",
    "            if batch_norm: # Si se usa normalización por lotes, se añade la capa de normalización\n",
    "                layers.append(nn.BatchNorm2d(first_conv_filters)) # Capa de normalización por lotes\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0)) # Capa de max pooling\n",
    "            layers.append(nn.ReLU()) # Capa de activación ReLU\n",
    "            input_channels = first_conv_filters # Actualiza el número de canales de entrada para la siguiente capa convolucional\n",
    "            first_conv_filters *= 2 # Duplica el número de filtros para la siguiente capa convolucional\n",
    "        \n",
    "        # Capa de convolución final\n",
    "        self.conv = nn.Sequential(*layers) # Capa convolucional compuesta por las capas definidas en el bucle anterior\n",
    "        \n",
    "        # Capa de aplanamento\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # MLP (AÑADIR LO DE MLP)\n",
    "        layers_mlp = []\n",
    "        self.mlp = nn.Sequential(*layers_mlp )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d220d9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo ten 19,008 parámetros\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso \n",
    "\n",
    "cnn = CNN(\n",
    "    input_channels=1,\n",
    "    conv_lavers=2,\n",
    "    first_conv_filters=32,\n",
    "    conv_kernel_size=3,\n",
    "    batch_norm=True,\n",
    "    hidden_mlp_layers=128,\n",
    "    output_neurons=10\n",
    ")\n",
    "\n",
    "def get_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"O modelo ten {get_parameters(cnn):,} parámetros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51fe19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dataloader = DataLoader(dataset=training_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3f14509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     train_loss = \u001b[43mtrain\u001b[49m(train_dataloader, cnn, loss_fn, optimizer)\n\u001b[32m      5\u001b[39m     train_losses_cnn.append(train_loss.item())\n\u001b[32m      7\u001b[39m test_predicted_classes_cnn, test_true_classes_cnn = test(test_dataloader, cnn)\n",
      "\u001b[31mNameError\u001b[39m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train_losses_cnn = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_dataloader, cnn, loss_fn, optimizer)\n",
    "    train_losses_cnn.append(train_loss.item())\n",
    "\n",
    "test_predicted_classes_cnn, test_true_classes_cnn = test(test_dataloader, cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
